<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: talks | Brandon Walsh]]></title>
  <link href="http://walshbr.com/categories/talks/atom.xml" rel="self"/>
  <link href="http://walshbr.com/"/>
  <updated>2019-06-20T19:28:02+00:00</updated>
  <id>http://walshbr.com/</id>
  <author>
    <name><![CDATA[{"name"=>"Brandon Walsh", "url"=>"https://twitter.com/mdo", "email"=>"walsh@virginia.edu"}]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[(DH) Public Speaking]]></title>
    <link href="http://walshbr.com/blog/dh-public-speaking/"/>
    <updated>2018-11-26T15:17:00+00:00</updated>
    <id>http://walshbr.com/blog/dh-public-speaking</id>
    <content type="html"><![CDATA[<p>This is a post that I had partially drafted on my laptop for a while, and I want to be better about getting things out in the world rather than sitting on them.</p>

<p>Part of my job involves helping students professionalize, as digital humanists and otherwise, which often means being there when students get accepted to their first digital humanities conference. Since most of my students come from the humanities, those conversations often go something like this:</p>

<blockquote>
  <p>Student: “I got accepted to the big digital humanities conference!” <br />
Me: “That’s exciting! You should be proud of yourself.”<br />
<strong>two months pass</strong> <br />
Student: “Wait what should I be expecting at this conference? People read their talks right?”<br />
Me: “Well…it’s complicated…”</p>
</blockquote>

<p>The answer, of course, is that it depends. In my experience, DH presentations seem to cover the full spectrum of approaches to public speaking and vary pretty widely depending on the conference. A DH talk at a discipline-specific conference is likely to be different than a DH talk at a mostly DH event. Some people dutifully read a talk they have written ahead of time. I would say most speakers get by with talking from notes, giving a presentation that is more or less extemporaneous. Some seem to speak fully off the cuff with little preparation and pull it off with style (not something I could do). Personal styles vary a lot, and giving a keynote is somewhat different than giving a roundtable response or a short paper presentation. Arguments about which approach is the best can be <em>fierce</em>.</p>

<p>The topic reminds me of a conversation I had with an undergraduate mentor back when I was just coming into graduate school and was accepted to my first conference. I had no real experience with academia at all - no friends or family who had worked on graduate degrees that were not pre-professional, and no humanities grads in my network. So I did not know what an abstract was, what a talk was, or how the two related with each other. After all, these behaviors and institutions all have to be learned sometime and somehow.</p>

<p>So on the off chance that this information is useful to someone out there I thought I would make a few notes about the way I go about preparing for talks, particularly because the way I do so is probably not immediately legible based on the end product. The way I do things feels somewhat idiosyncratic, which hopefully makes it all the more worth sharing. I finally decided it was worth doing so after walking around the Chicago airport prepping for my DH 2018 talk.</p>

<h2 id="reading-a-talk--giving-a-talk-from-notes">Reading a Talk / Giving a Talk from Notes</h2>

<p>To begin, it might be helpful to compare the two main approaches to giving DH talks that I outlined above. I think they probably hold true for most forms of public speaking, though one genre of talk might be less socially accepted depending on your context and your audience.</p>

<p><strong>When reading a written paper…</strong></p>

<ul>
  <li>You are more likely to stick to the time limit. It is easier to plan when you know each page is roughly two minutes.</li>
  <li>You already have something written up that can easily be repurposed or shared online. It is harder to get back in the conference headspace and write a thing up with every passing moment after a conference.</li>
  <li>You will probably find the experience easier on the nerves, as all you have to do is keep reading and talking. Before you know it, the bulk of the talk will be done.</li>
  <li>You can seem quite dull unless you take steps to perform your reading very well. This point is probably the main objection to reading a talk. After all, it is hard to stay engaged when someone is just reading aloud for 15 to 20 minutes (let alone an hour). This is not universally true - some people are quite adept at performing their reading of a presentation. And some (non-DH contexts in particular) virtually expect you to be reading your talk.</li>
  <li>But, then again, you will actually say everything you mean to say in the order you mean to say it. That is worth a lot!</li>
</ul>

<p><strong>When speaking from notes…</strong></p>

<ul>
  <li>You are more likely to be engaging. It is easier for you to inject a sense of personality in your talk. Again, this is usually the big advantage of the approach to people.</li>
  <li>It is more difficult to predict how long you will talk for. If you take out the rough rule of two minutes to a 12-point Times New Roman page it is more difficult to know exactly what you are in for. Will you get through everything? Will you run out of time?</li>
  <li>Beyond pace, you might leave something out, or you might not say something in exactly the best way to express your ideas.</li>
  <li>You will not necessarily have a written product ready to go at the end, so that makes more work for you if you want to share the talk.</li>
</ul>

<p>I think it is far more common in digital humanities to speak from notes. People have quite strong opinions about the delivery of talks, but I have always felt that there is no one correct answer. In one context you might see someone looked down upon for reading, but in that same venue a speaker might try and go from notes, go way over time, and never get through more than the introduction. Both can be done well, and both can be done poorly.</p>

<h2 id="write-and-then-listen">Write and then Listen</h2>

<p>I do not write this to convince anyone that one form is better - I always feel like the conversation depends on a lot of personal factors. How anxious does public speaking make you? What makes you most comfortable? What social, personal, or medical circumstances might wholly rule out one approach for you? I more wanted to share my approach, which tries to split the differences. I should say at the outset that I am not necessarily advocating this for everyone. It feels a bit strange, but it is a workflow that I have come to like quite a lot. Hopefully it’s useful for someone out there as well.</p>

<p>The workflow I use to prepare has its roots in my own learning habits that go back to grade school - I have always found it easier to learn things by listening rather than by reading. When learning things for tests growing up I always needed to say them aloud - get them in my mouth and in my ear. And now I do it as a professional. If it was good enough for me in sixth grade it is good enough for me as an adult. The process I use to prepare for long-form public speaking (usually anything longer than 5-6 minutes) draws upon a similar process of making the work audible:</p>

<ol>
  <li>I write the talk.</li>
  <li>I record myself giving the talk and make an MP3 of it using <a href="https://www.audacityteam.org/">audacity</a>.</li>
  <li>I use <a href="https://www.ronimusic.com/">The Amazing Slow Downer</a>, a great tool used by musicians, to divide up the talk into sections.</li>
  <li>I listen to the segments of that MP3 a bunch of times while walking around the airport, doing chores, driving, etc.</li>
  <li>Practicing a talk usually entails trying to learn pieces of the talk.</li>
  <li>When giving the talk I have the written version for reference if needed, but I usually don’t need to look at it much.</li>
</ol>

<p>The Amazing Slow Downer allows you to do all sorts of useful things with audio to facilitate learning things by ear. You are probably not going to use most of its features if learning a talk, but it does have a pretty handy slicing and looping tool that can make it easier to divide a talk into segments and learn one piece at a time. If you are trying to learn music you can also slow things down without changing the pitch so as to pick things apart one note at a time.</p>

<p>Writing a talk is one thing. Learning and delivering it are another. The process for me is pretty similar to learning a song by listening to it on repeat. By the time I give the talk the thing has been rattling around in my head for days or weeks. I am usually just as excited to get the content out of my head and move on with my life as I am to actually discuss the material. I do not ever quite memorize the talks, but I do come close in a lot of cases. The good thing, though, is that I do not really need to memorize them. I can always bring the written talk with me anyway, and I usually do. Because I have already listened to the piece a lot and tried to learn it I only need to look down every five or six sentences to jog my memory. Each listen to the talk ahead of time is one fewer times I will have to look down at the sheet in the moment.</p>

<p>The result is a good middle road for me where I feel like I get the best of both worlds. I walk away with a blog post ready to go, and the timing is easier to plan for. I think I am much more engaging this way than when I read straight up, and it calms my nerves to know that I have prepared enough that the talk has earwormed its way into my head. If I get <em>really</em> panicked I can always just look down and grab the next set of sentences.</p>

<p>As with all things, your mileage may vary. But if this post does nothing other than spread the word about The Amazing Slow Downer I will consider it a success. It is a really nifty tool, especially when paired with Audacity.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Praxis and Scale: On The Virtue of Small]]></title>
    <link href="http://walshbr.com/blog/praxis-and-scale-on-the-virtue-of-small/"/>
    <updated>2018-06-15T09:26:00+00:00</updated>
    <id>http://walshbr.com/blog/praxis-and-scale-on-the-virtue-of-small</id>
    <content type="html"><![CDATA[<p><em>The following is a version of my talk for DH2018 that will be given as a part of a roundtable on Digital Humanities Pedagogy and Praxis. Participants on the panel responded to a <a href="http://praxis-network.org/dh2018/">CFP</a> marking five years since we launched the <a href="http://praxis-network.org/">Praxis Network</a>.</em></p>

<p><img src="/assets/images/praxis-and-scale/1.jpeg" alt="title slide" /></p>

<p>I am Brandon Walsh, the Head of Graduate Programs at the Scholars’ Lab in the University of Virginia Library in the United States. Today I want to talk about a tension I see in DH pedagogy between the hands-on, student-driven instruction that we’re discussing here as part of the Praxis Network and the scale at which we can offer it. Can we take what started small and scale it up in an ethical and informed way? In particular, I want to suggest that “small” investments in pedagogy driven by students are worth it, that we should resist uncritical calls to scale up the reach of our praxis, and that we can best measure the growth of our programs by the degree to which our students are empowered to become engaged, generous teachers in their own right.</p>

<p><img src="/assets/images/praxis-and-scale/2.jpeg" alt="praxis program summary" /></p>

<p>My own local context for this talk is the Scholars’ Lab’s <a href="http://praxis.scholarslab.org/">Praxis Program</a>, which offers a targeted digital humanities injection during the early years of a student’s graduate work. In the Praxis Program each year, staff and faculty work alongside a student cohort to theorize a new digital intervention and to train the students to implement it themselves. We shift from a series of workshops and discussions in the fall semester to a lab model in the spring, from the staff in front of the room to all of us working together to get a thing done. Funding for the program comes from the library in the form of teaching releases for the students, and I’m happy to talk more about these practical details in the Q&amp;A. The program aims to equip graduate students with the skills and ethos necessary to thrive when carrying out collaborative, open work that might happen on or off the tenure track, and, drawing upon the pedagogical theories of Cathy Davidson, Paolo Freire, Bethany Nowviskie, and others, we do this by putting the students in charge, allowing them as much as possible to decide what they work on and how they’ll work on it.</p>

<p>This panel invites us to reflect on how student programs like these have changed in the past several years, on their triumphs and difficulties. Now in its seventh year, we measure the Praxis Program’s success by a number of metrics - exit interviews, job placements, future awards received by our alumni, and publications.</p>

<p><img src="/assets/images/praxis-and-scale/3.jpeg" alt="praxis projects slide" /></p>

<p>We’ve assembled a <a href="http://praxis.scholarslab.org/projects">series of projects</a> of varying shapes and sizes, conceived and developed by the students themselves and with various afterlives, and a host of alumni who have gone on to build on their time with us. But we sometimes get questions or comments about the program’s scale.</p>

<p><img src="/assets/images/praxis-and-scale/4.jpeg" alt="scale slide with image of empty chairs" /></p>

<p>Each cohort consists of six students. Pretty small compared to a traditional course that might engage a single instructor, and, what’s more, this program draws in virtually all of our staff at one time or another. That is a significant investment of resources in a small group of students each year. Over the years we’ve been asked about the limits of the model from a number of people, inside and outside UVA. Can we have a second cohort of students each year? Could we take the model and grow it?</p>

<p>They’re reasonable asks, but they raise a number of issues for me that I hope might be useful for any student program. The first is simple – can a model like this grow? Although we have some <a href="http://praxis.scholarslab.org/resources/">recurring units, lessons, and resources</a> each year, the student-driven nature of the Praxis Program requires us to embrace the unexpected. <a href="http://reveal.scholarslab.org/">This last year</a>, for example, we started out with one idea but reversed course and rebuilt the curriculum based on the unfolding interests of our students.</p>

<p><img src="/assets/images/praxis-and-scale/5.jpeg" alt="image of Praxis resources and curriculum published online" /></p>

<p>This requires a serious commitment of time and resources - it can be difficult to predict exactly which staff members will be the primary points of contact for the project, and responsibilities might change unexpectedly. There is also a question of capacity. We are limited in the number of students that we can maintain at any one time and still carry out our other obligations as a library unit. I should note here that there are powerful examples of people doing this kind of engaged student work on a large scale - the <a href="https://www.hastac.org/groups/hastac-futureed">#FutureEd initiative</a> by Davidson and others is a clear example, and instructors in the sciences are often already working at a much larger scale when they try to implement similar approaches in their lecture courses. Numbers might be part of a necessary approach to your own critically engaged pedagogy.</p>

<p>Another question - should it grow? Perhaps rather than expanding a single working model, resources might be better served in other areas, other programs, other people - more on that in a moment. For our group, at least, keeping a smaller program that centers project-based education is a strategic investment in the individual as a meaningful point of intervention. The core of our work, more than any digital project, is the people, who we try empower to act as DH professionals and pay their lessons forward from day one. Far from limiting our impact, I think that deliberately staying small attempts to do more with less, to invest in the futures of these students as they become teachers themselves. We believe in the grassroots impact these young people can have on the field and on their communities.</p>

<p>And finally - how should it grow? Most importantly, to me at least, is that we continue to develop educational experiences that are as equitable and just as possible. In my experience, conversations around scale aren’t usually met with offers for more resources. And we should not let calls to grow tempt us into uncritically adopting volunteer labor or unpaid internships. <a href="http://cdh.ucla.edu/news/a-student-collaborators-bill-of-rights/">UCLA’s Student Collaborator’s Bill of Rights</a> is a touchstone here. Students might be willing to volunteer their time with you for the sake of the experience, but our position is that we should resist those offers. There is plenty of evidence to suggest that allowing such unpaid labor reinforces socioeconomic and racial disparities in the workforce. We try not to grow beyond our ability to fund our students.</p>

<p>I want to pause momentarily to recognize that this is a fairly privileged conversation. The Scholars’ Lab programs are in the fortunate position to be well funded at the time of this writing, and (even at my own institution) there are many units and individual people tasked with raising programs from the ground on little to no funding. I’m sure there are some of you in the room in that same position. My colleagues and I are fortunate. Ours is not the only way to shape a program, and it’s certainly not the best one for every institutional context. I hope, however, that this conversation might offer those of you making difficult decisions about resources a model – or, at least, a series of ideas – to consider. You don’t need an extensive reach or a robust cohort of students to make something meaningful happen. If you can fund one student – that is worth doing. Embrace the fact that you can engage that one person in the important work of developing and growing your program. Do what you can with what you can, but, again, we should collectively resist calls to grow student programs beyond our capacity to resource and sustain them.</p>

<p>I think a lot about the disparate amounts of privilege some of our students enjoy, and much of our effort is spent trying to scale our impact in ways that broaden access even though we can’t afford a deep dive with many students. This means offering a diverse range of ways in for students, with other <a href="http://scholarslab.org/graduate-fellowships/">opportunities</a> for engaging our community that might be more targeted and more sustainable. It also means engaging alumni of the Praxis Program in our other initiatives, folding their strengths into our pool of resources and giving them opportunities to explore themselves as teachers. We try to engage these students who have been able to access our resources, time, and knowledge in helping their colleagues who might not have benefited from the same.</p>

<p><img src="/assets/images/praxis-and-scale/6.jpeg" alt="image of LAMI program fellows" /></p>

<p>Since the Praxis Program’s inception, for example, we have partnered with our campus’s version of the <a href="https://graddiversity.virginia.edu/U.Va.LAMI">Leadership Alliance Mellon Initiative (LAMI)</a> to pilot a complimentary program in DH and library research methods for undergraduates from underrepresented communities with the assistance of our Praxis alumni. The undergraduates taking part in this program are thinking about graduate school, and our contribution is to give them just a taste of what research at that level might look like for them. Our Praxis alumni lead a workshop for them, participate in discussions, and also show what the next phase of life after undergraduate can look like.</p>

<p>I’ve talked a bit about our past and present. A single thought on the future of our programs it would be this - I think it is incumbent upon us to turn our work outwards and think about the impact our students can have on a broader community beyond our institution - that’s where the Scholars’ Lab has been heading, and I’d like to continue in that direction. In the direction of out rather than in.</p>

<p><img src="/assets/images/praxis-and-scale/7.jpeg" alt="List of student workshops at Washington and Lee" /></p>

<p>One way in which we’ve tried to do this is to work more closely with institutions in the region. We’ve partnered with Washington and Lee for a few years now to engage students as guest DH workshop leaders on their campus, and we’re soon hoping to expand to University of Richmond as well. We ask our students to blog about these workshops, and we have been accumulating a <a href="https://digitalhumanities.wlu.edu/blog/category/uva-collaboration/">list of these resources</a> for others to learn from or build upon. Similarly, I would like to extend the work of our students to the local Charlottesville community, <a href="https://news.library.virginia.edu/2018/06/18/library-receives-grant-from-lyrasis-for-digital-collecting-in-times-of-crisis/">something the Lab has been increasingly engaged in</a>, but I would like us to be more deliberate about incorporating students as we do so. We can continue to empower student research but do so as part of the Lab’s mission of promoting access, sharing resources, and advancing social justice.</p>

<p><img src="/assets/images/praxis-and-scale/8.jpeg" alt="Title slide redone" /></p>

<p>If I have one point today point it is this - there are limits to the number of deep dives you can take. But they can serve as excellent starting points for other schemes - you can do a lot with a little. Our former director, Bethany Nowviskie, once used the phrase “too small to fail” to describe our approach to graduate education. Small can still have a big impact. At the Scholars’ Lab, I’d like our own particular brand of small to be public, engaged, and local, empowering students who feel confident but also compelled to give back to their peers, students, and neighborhoods. Weighing ourselves in this way, by the degree to which we help to democratize and provide access to these sorts of methods, questions, and technologies ultimately feels more meaningful than doing so by the number of students we reach.</p>

<p>References and Further Reading</p>

<ul>
  <li>A Student Collaborators’ Bill of Rights. University of California Los Angeles Center for Digital Humanities. <a href="http://cdh.ucla.edu/news/a-student-collaborators-bill-of-rights/">http://cdh.ucla.edu/news/a-student-collaborators-bill-of-rights/</a></li>
  <li>#FutureEd. Humanities, Arts, Science, and Technology Alliance and Collaboratory. <a href="https://www.hastac.org/initiatives/futureed">https://www.hastac.org/initiatives/futureed</a></li>
  <li>Davidson, C. (2017). The New Education: How to Revolutionize the University to Prepare Students for a World In Flux. New York, NY: Basic Books.</li>
  <li>Freire, P. (1970). Pedagogy of the Oppressed. New York, NY: Bloomsbury Academic.</li>
  <li>Nowviskie, B. (2011). “Praxis and Prism.” <a href="http://nowviskie.org/2011/praxis-and-prism/">http://nowviskie.org/2011/praxis-and-prism/</a>
———. (2012). “Too Small To Fail.” <a href="http://nowviskie.org/2012/too-small-to-fail/">http://nowviskie.org/2012/too-small-to-fail/</a></li>
  <li>Rogers, K. (2015). “Humanities Unbound: Supporting Careers and Scholarship Beyond the Tenure Track.” Digital Humanities Quarterly 9.1.</li>
  <li>The Praxis Program. University of Virginia Library’s Scholars’ Lab. <a href="http://praxis.scholarslab.org">http://praxis.scholarslab.org</a>.</li>
  <li>The Praxis Network. University of Virginia Library’s Scholars’ Lab. <a href="http://praxis-network.org/">http://praxis-network.org/</a>.</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Frustration is a Feature]]></title>
    <link href="http://walshbr.com/blog/frustration/"/>
    <updated>2018-01-03T09:44:00+00:00</updated>
    <id>http://walshbr.com/blog/frustration</id>
    <content type="html"><![CDATA[<p><em>The following talk was given at MLA18 as a part of Panel 203: Anxious Pedagogies - Negotiating Precarity and Insecurity in the Classroom. Technically I suppose the title should be “Anxiety Is a Feature,” but the alliteration was too tempting.</em></p>

<p><img src="/assets/images/frustration/1.jpg" alt="title slide" /></p>

<p>Thanks for putting this panel together, Shawna. And thanks, all of you, for your thoughts - I’ve learned a lot from our exchanges leading up to this panel.</p>

<p><img src="/assets/images/frustration/2.jpg" alt="Text: &quot;What are you teaching you're students?&quot;" /></p>

<p>I’m the Head of Graduate Programs in the Scholars’ Lab, a digital humanities center at the UVA Library. I want to come at the question of anxious pedagogies from the perspective of my role in the lab, where I often teach programming and DH skills and methods in addition to my primary duties, which are developing and administering the lab’s educational and professional development programs for graduate students. I work with students very self-consciously trying to step outside of their comfort zones, and I’d like to think about the anxieties associated with these cases in particular.</p>

<p>I want to ask what, exactly, it is that we’re teaching our students. If you’re a sighted reader of English, your skin has probably been crawling due to the grammatical error in my slide here. And that’s part of the point - this error is the subject of memes (but it’s one I constantly make in emails). You might be embarrassed for me and wish someone had pointed it out to me ahead of time. Let’s explore that.</p>

<p><img src="/assets/images/frustration/3.jpg" alt="Basic Python syntax error" /></p>

<p>There’s a Python error of a similar kind in this slide. In programming, such small mistakes are major issues that can cause a project to fail. They’re also common for beginning programmers and DHers. A student has an error like this, and, quite understandably, they ask for help from the teacher. The instructor, as a human being, quite understandably wants to help. I want to talk about that moment - the point at which a student needs help and the nature of the contribution that we as colleagues and mentors are prepared to give.</p>

<p>The ability to identify the kinds of problems I’m pointing out depends a lot on background and training. To expect such problems to be immediately identifiable makes a lot of assumptions about education, literacy, and background that no instructor should make. This is as true of the first example as in the second, which expects that someone has a background in programming and so knows that a computer would not be able to infer a relationship between the variables ‘fruit’ and ‘fruits’ - adding the extra ‘s’ in that last line by accident causes problems.</p>

<p><img src="/assets/images/frustration/4.jpg" alt="XKCD comic about how every day 10,000 people learn something for the first time." /></p>

<p>I have seen so many students stare, with mounting frustration, at chunks of code, feeling that they are beyond them, that issues in code represent some failing on their own part rather than a natural part of programming (we all make mistakes). Sure, my job is to teach them the skills with which they can solve these problems - the syntax that will prevent such errors in the future. But it’s also to help them recognize that no one is born knowing this stuff. Born knowing anything. And that such anxieties and frustrations are part of what all of us all deal with on a regular basis.</p>

<p>I am not suggesting that we should approach such student frustration as feelings to be worked past or to be toughed out. Instead I want to suggest that the most important, radical act that we can make as teachers is to center frustration and anxiety in our teaching. This feeling, that of knowing something is there but not seeing it, or of knowing something is wrong but not how to address it, are central to the very idea of what it means to learn and to teach. Sianne Ngai might call these “ugly feelings” - those feelings that lead to no cathartic action and that are associated, instead, with pause, frustration, and paralysis.</p>

<p>I’d suggest that our primary role as teachers is not to teach any particular content. Nor is our primary role to teach methods. Our ultimate aim should be to help students learn how to learn, how to keep going with the material outside the context of our courses. And, importantly, how to do this work with, through, and alongside such difficult emotions.</p>

<p>In DH we often valorize failure and what can be learned from it, but it can be difficult to know how to deal with the feelings associated with it. I’ve tried to develop exercises (drawing upon the work of <a href="http://waynegraham.github.io/">Wayne Graham</a>, <a href="http://jeremyboggs.net/">Jeremy Boggs</a>, <a href="http://literaturegeek.com/">Amanda Visconti</a>, and <a href="http://nowviskie.org/">Bethany Nowviskie</a>) that help students sit with and think through the frustration and anxiety associated with failure. To teach web design, I ask students to draw a series of prototypes for websites using pencil and paper, some explicitly designed to fail, so as to develop a better sense of what it might mean for a website to succeed. Or I ask students to explore a set of programming exercises that have bugs artificially introduced to them as a way of helping them learn concrete steps for exploring problems in the face of mounting anxiety.</p>

<p>I’d love to hear from all of you if you have any thoughts for how to center, rather than expel, frustration and anxiety from teaching, learning, and the classroom. These issues are especially salient while teaching programming to humanists, as the interdisciplinary nature of it requires people step out of their comfort zone. But as others on this panel have articulated so well, these issues extend to the whole person. Beyond the content we teach and the act of learning it - our students are living in states of continual anxiety. To say nothing of the personal, social, or systemic traumas to which many of them have been subjected about which we may never know.</p>

<p>Most of what we do in the Scholars’ Lab is help students navigate these situations in a professional context. Most of what I do tends to revolve around convincing students that they are good enough. That they are qualified enough to <a href="http://scholarslab.org/visiting-workshops-at-washington-and-lee-university/">teach a workshops on DH</a> or <a href="http://scholarslab.org/professional-development/">to apply for any number of DH or alt-ac jobs</a>.  That a little goes a long way. That imposter syndrome is something felt by everyone. That their work has worth.</p>

<p>There are a number of things we can do as administrators to help mitigate the anxieties of our students. Advocate for them by actively campaigning for the bureaucratic status to serve on committees, teach courses, and offer them the support that they need. Petition our legislatures and administrations for more just labor relations. Figure out the small bureaucratic things that translate to big pains for our students - things like delayed payments, long turnarounds on applications, gatekeeping practices.</p>

<p>My point, our point, really, is that our students and colleagues are consistently in positions of anxiety and frustration - in and out of the classroom. So I’d ask what can we do to make our institutions, our classrooms, and our one-on-one interactions with our students more empathetic, but also more consciously aware of and engaged in the negative emotions they might bring out. Because as the title of this short talk suggests - frustration and anxiety are not pedagogical bugs. They are features. Woven into the very texture of what it means to be human and to be a learner. The question is - what are we prepared to do about it?</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Collaborative Writing to Build Digital Humanities Praxis]]></title>
    <link href="http://walshbr.com/blog/collaborative-writing-to-build-digital-humanities-praxis/"/>
    <updated>2017-08-04T14:40:00+00:00</updated>
    <id>http://walshbr.com/blog/collaborative-writing-to-build-digital-humanities-praxis</id>
    <content type="html"><![CDATA[<p><em>[The following is the rough text of my short paper given at the 2017 Digital Humanities conference in Montréal.]</em></p>

<p><img src="/assets/images/collaborative-writing/1.jpg" alt="title slide" /></p>

<p>Thanks very much for having me today! I’m Brandon Walsh, Head of Graduate Programs in the Scholars’ Lab at the University of Virginia Library. I’ll be talking a bit today about “Collaborative Writing to Build Digital Humanities Praxis.” Since the subject here is collaboration I wanted to spend a few minutes here on my collaborators.</p>

<p><img src="/assets/images/collaborative-writing/2.jpg" alt="thank you slide" /></p>

<p>This work was begun at my previous position at Washington and Lee University’s library. My principal collaborator here is and was Professor Sarah Horowitz, from Washington and Lee University. We conceived the project together, co-taught the associated course, and her writing figures prominently on the project I will describe. The other names here are individuals, institutions, or projects who figure explicitly in the talk, whether they know it or not. You can find a Zotero collection with the resources mentioned during the talk <a href="http://goo.gl/2CuWj7">here</a>.</p>

<p>So. To begin. Emergent programs like those associated with the <a href="http://praxis-network.org">Praxis Network</a> have redefined the possibilities for digital humanities training by offering models for project-based pedagogy. These efforts provide innovative institutional frameworks for building up and sharing digital skills, but they primarily focus on graduate or undergraduate education. They tend to think in terms of students. The long-term commitments that programs like these require can make them difficult to adapt for the professional development of other librarians, staff, and faculty collaborators. While members of these groups might share deep interests in undertaking such programs themselves, their institutional commitments often prevent them from committing the time to such professional development, particularly if the outcomes are not immediately legible for their own structures of reporting. I argue that we can make such praxis programs viable for broader communities by expanding the range of their potential outcomes and forms. In particular, I want to explore the potential for collaborative writing projects to develop individual skillsets and, by extension, the capacity of digital humanities programs.</p>

<p><img src="/assets/images/collaborative-writing/3.jpg" alt="coursebook site" /></p>

<p>While the example here focuses on a coursebook written for an undergraduate audience, I believe the model and set of pedagogical issues can be extrapolated to other circumstances. By considering writing projects as potential opportunities for project-based development, I argue that we can produce professionally legible outcomes that both serve institutional priorities and prove useful beyond local contexts.</p>

<p>The particular case study for this talk is an <a href="http://walshbr.com/textanalysiscoursebook">open coursebook</a> written for a course on digital text analysis (Walsh and Horowitz, 2016). In fall of 2015, Professor Sarah Horowitz, a colleague in the history department at Washington and Lee University, approached the University Library with an interest in digital text analysis and a desire to incorporate these methods in her upcoming class. She had a growing interest in the topic, and she wanted support to help her take these ideas and make them a reality in her research and teaching. As the Mellon Digital Humanities Fellow working in the University Library, I was asked to support Professor Horowitz’s requests because of my own background working with and teaching text analysis. Professor Horowitz and I conceived of writing the coursebook as a means by which the Library could meet her needs while also building the capacity of the University’s digital humanities resources. The idea was that, rather than offer her a handful of workshops, the two of us would co-author materials together that could then be used by Professor Horowitz later on. The writing of these materials would be the scene of the teaching and learning. Our model in this regard was as an initiative undertaken by the Digital Fellows at the CUNY Graduate Center, where their Graduate Fellows produce documentation and shared digital resources for the wider community. We aimed to expand upon their example, however, by making collaborative writing a centerpiece of our pedagogical experiment.</p>

<p><img src="/assets/images/collaborative-writing/4.jpg" alt="tech stack" /></p>

<p>We included Professor Horowitz directly in the creation of the course materials, a process that required her to engage in a variety of technologies central to a certain kind of web publishing workflow: command line, Markdown, Git, and GitHub. We produced the materials on a platform called <a href="https://www.gitbook.com/">GitBook</a>, which provides a handy interface for writing that invokes many elements of this tech stack in a non-obtrusive way. Their editor allows you to write in markdown and previews the resultant text for you, but it also responds to the standard slew of MS Word keyboard shortcuts that many writers are familiar with. In this way we were able to keep the focus on the writing even as we slowly expanded Professor Horowitz’s ability to work directly with these technologies. From a writing standpoint, the process also required synthesis of both text analysis techniques and disciplinary material relevant to a course in nineteenth-century history. I provided the former, Professor Horowitz would review and critique as she added the latter, then I would review, etc. The result, I think, is more than either of us could have produced on our own, and we each learned a lot about the other’s subject matter. The result of the collaboration is that, after co-writing the materials and teaching the course together, Professor Horowitz is prepared to offer the course herself in the future without the support of the library. We now also possess course materials that, through careful structuring and selection of platforms, could be reusable in other courses at our own institutions and beyond. In this case, we tried to take special care to make each lesson stand on its own and to compartmentalize each topic according to the various parts of each class workshop. One section would introduce a topic from a theoretical standpoint, the next would offer a case study using a particular tool, and the last would offer course exercises that were particular to our course. We hoped this structuring would make it easy for the work to be excerpted and built upon by others for their own unique needs.</p>

<p><img src="/assets/images/collaborative-writing/5.jpg" alt="table of contents" /></p>

<p>Writing collaborations such as these can fit the professional needs of people in a variety of spaces in the university. Course preparation, for example, often takes place behind the scenes and away from the eyes of students and other scholars. You tend to only see the final result as it is performed with students in a workshop or participants in a class. With a little effort, this hidden teaching labor can be transformed into openly available resources capable of being remixed into other contexts. We are following here on the example of Shawn Graham (2016), who has illustrated through his own resources for a class on <a href="http://workbook.craftingdigitalhistory.ca/">Crafting Digital History</a> that course materials can be effectively leveraged to serve a wider good in ways that still parse in a professional context. In our case, the collaboration produced public-facing web writing in the form of an open educational resource. The history department regarded the project as a success for its potential to bring new courses, skills, and students into the major as a result of Professor Horowitz’s training. The University Library valued the collaboration for its production of open access materials, development of faculty skills, and exploration of workflows and platforms for faculty collaboration. We documented and managed the writing process in a <a href="https://github.com/walshbr/introduction-to-text-analysis">GitHub repository</a>.</p>

<p><img src="/assets/images/collaborative-writing/6.jpg" alt="GitHub repository" /></p>

<p>This versioned workflow was key to our conception of the project, as we hoped to structure the project in such a way that others could copy down and spin up their own versions of the course materials for their own needs. We were careful to compartmentalize the lessons according to their focus on theory, application, or course exercises, and we provided <a href="http://walshbr.com/textanalysiscoursebook/book/conclusion/adapting/">documentation</a> to walk readers through the technical process of adapting the book to reflect their own disciplinary content. We wrote reasonably detailed directions aimed at two different audiences - those with a tech background and those without. We wanted people to be able to pull down, tear apart, and reuse those pieces that were relevant for them. We hoped to create a mechanism by which readers and teachers could iterate using our materials to create their own versions.</p>

<p><img src="/assets/images/collaborative-writing/7.jpg" alt="Adapting the Book" /></p>

<p>Writing projects like this one provide spaces for shared learning experiences that position student and teacher as equals. By writing in public and asking students and faculty collaborators to discuss, produce, and revise open educational resources, we can break down distinctions between writer and audience, teacher and student, programmer and non-programmer. In this spirit, work by Robin DeRosa (2016) with the <a href="https://openamlit.pressbooks.com/">Open Anthology of Earlier American Literature</a> and Cathy Davidson with HASTAC has shown that students can make productive contributions to digital humanities research at the same time that they learn themselves. These contributions offer a more intimate form of pedagogy – a more caring and inviting form of building that can draw newcomers into the field by way of non-hierarchical peer mentoring. It is no secret that academia contains “severe power imbalances” that adversely affect teaching and the lives of instructors, students, and peers (McGill, 2016). I see collaborative writing as helping to create shared spaces of exploration that work against such structures of power. They can help to generate what Bethany Nowviskie (2016) has recently advocated as a turn towards a “feminist ethics of care” to “illuminate the relationships of small components, one to another, within great systems.” By writing together, teams engage in what Nowviskie (2011) calls the “perpetual peer review” of collaborative work. Through conversations about ethical collaboration and shared credit early in the process, we can privilege the voice of the learner as a valued contributor to a wider community of practitioners even before they might know the technical details of the tools or skills under discussion.</p>

<p>Collaborative writing projects can thus serve as training in digital humanities praxis: they can help introduce the skills, tools, and theories associated with the field, and projects like ours do so in public. Productive failure in this space has long been a hallmark of work in the digital humanities, so much so that “Failure” was listed as a keyword in the new anthology Digital Pedagogy in the Humanities (Croxall and Warnick, 2016). Writing in public carries many of the same rewards – and risks. Many of those new to digital work, in particular, rightfully fear putting their work online before it is published. The clearest way in which we can invite people into the rewards of public digital work is by sharing the burdens and risks of such work. In her recent work on generous thinking, Kathleen Fitzpatrick (2016) has advocated for “thinking with rather than reflexively against both the people and the materials with which we work.” By framing digital humanities praxis first and foremost as an activity whose successes and failures are shared, we can lower the stakes for newcomers. Centering this approach to digital humanities pedagogy in the practice of writing productively displaces the very digital tools and methodologies that it is meant to teach. Even if the ultimate goal is to develop a firm grounding in a particular digital topic, focusing on the writing invites students and collaborators into a space where anyone can contribute. By privileging the writing rather than technical skills as the means of engagement and ultimate outcome, we can shape a more inviting and generous introduction to digital humanities praxis.</p>

<p><strong>References</strong></p>

<ul>
  <li>Croxall, B. and Warnick, Q. (2016). “Failure.” In Digital Pedagogy in the Humanities: Concepts, Models, and Experiments. Modern Languages Association.</li>
  <li>DeRosa, R. (2016). “The Open Anthology of Earlier American Literature.” https://openamlit.pressbooks.com/.</li>
  <li>Fitzpatrick, K. (2016). “Generous Thinking: The University and the Public Good.” Planned Obsolescence. http://www.plannedobsolescence.net/generous-thinking-the-university-and-the-public-good/.</li>
  <li>Graham, S. (2016). “Crafting Digital History.” http://workbook.craftingdigitalhistory.ca/.</li>
  <li>McGill, B. (2016). “Serial Bullies: An Academic Failing and the Need for Crowd-Sourced Truthtelling.” Dynamic Ecology. https://dynamicecology.wordpress.com/2016/10/18/serial-bullies-an-academic-failing-and-the-need-for-crowd-sourced-truthtelling/.</li>
  <li>Nowviskie, B. (2011). “Where Credit Is Due.” http://nowviskie.org/2011/where-credit-is-due/.</li>
  <li>———. 2016. “Capacity Through Care.” http://nowviskie.org/2016/capacity-through-care/.
Ramsay, S. (2010). “Learning to Program.” http://stephenramsay.us/2012/06/10/learning-to-program/.</li>
  <li>———. 2014. “The Hermeneutics of Screwing Around; or What You Do with a Million Books.” In Pastplay: Teaching and Learning History with Technology, edited by Kevin Kee. University of Michigan Press. http://hdl.handle.net/2027/spo.12544152.0001.001.</li>
  <li>The Praxis Network (2017). University of Virginia Library’s Scholars’ Lab. http://praxis-network.org/.
Walsh, Brandon, and Sarah Horowitz. 2016. “Introduction to Text Analysis: A Coursebook.” http://www.walshbr.com/textanalysiscoursebook</li>
</ul>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Remixing the Sound Archive: Cut-up Poetry Recordings]]></title>
    <link href="http://walshbr.com/blog/remixing-the-sound-archive/"/>
    <updated>2017-06-16T13:47:00+00:00</updated>
    <id>http://walshbr.com/blog/remixing-the-sound-archive</id>
    <content type="html"><![CDATA[<p><em>[Recently I spoke at NEMLA 2017 with <a href="http://www.sherwoodweb.org/">Ken Sherwood</a> and <a href="https://www.english.upenn.edu/people/chris-mustazza">Chris Mustazza</a>. The panel was on “Pedagogy and Poetry Audio: DH Approaches to Teaching Recorded Poetry/Archives,” and my own contribution extended some <a href="/blog/deformance-talk/">past experiments</a> with using deformance as a mode of analysis for audio recordings. The talk was given from notes, but the following is a rough recreation of what took place.]</em></p>

<p>Robust public sound archives have made a wide variety of material accessible to students and researchers for the first time, and they provide helpful records of the history of poetic performance throughout the past century. But they can also appear overwhelming in their magnitude, particularly for students: where to begin listening? How to begin analyzing any recording, let alone multiple recordings in relation to each other? This talk argues that we can help students start to explore these archives if we think about them as more than just an account of past performances: sound collections can provide the materials for resonant experiments in audio composition. I want to think about new ways to explore these archives through automatic means, through the use of software that algorithmically explores the sound collection as an object of study by tampering with it, dismantling it, and reassembling it. In the process, we might just uncover new interpretive dimensions.</p>

<p>This talk thus models an approach to poetry recordings founded in the deformance theories of Jerome McGann and Lisa Samuels and the cut-up techniques of the Dadaists. I prototype a pair of class assignments that ask students to slice up audio recordings of a particular poet, reassemble them into their own compositions, and reflect on the process. These acts of playful destruction and reconstruction help students think about poems as constructed sound objects and about poets as sound artists. By diving deeply into the extant record for a particular poet, students might produce performative audio essays that enact a reading of that artist’s sonic patterns. By treating sound archives as the raw ingredients for poetic remixes, we can explore and remake sound objects while also gaining new critical insight into performance practices. In the process of remixing the sound archive, we can encourage students to engage more fully with it. And while I frame this in terms of student work and pedagogy given the topic of the panel, it should become clear that I think of this as a useful research practice in its own right.</p>

<p>I will frame the interventions and theoretical frameworks I am making before proposing two different models for how to approach such an assignment depending on the instructor’s own technical ability and pedagogical goals: one model that uses Audacity and another that uses Python to cut and reassemble poetry recordings. I will demonstrate example compositions from the latter. It will get weird.</p>

<p><img src="/assets/images/nemla/slide02.jpg" alt="provocations for the talk" /></p>

<p>There are two provocations at the center of my talk founded in an assumption about the way students hear poetry recordings. In my experience, they often hear recordings not as sound artifacts but as representations of text. They might come to these recordings looking to hear the poet herself speak, or they might be looking to get new perspectives on the poem. But they fundamentally are interested in hearing a new version of a printed text, in hearing these things as analogues to print. This is all well and good - the connection to a text is clearly a part of what makes poetry recordings special, but I think our challenge as teachers and thinkers of poetry is to help students surface the sounded quality of the artifacts, to learn to dig deeper into digital sound in particular.</p>

<p><img src="/assets/images/nemla/slide03.jpg" alt="provocations 2 - work in the medium" /></p>

<p>My approach to this need - the need to get students to look beyond the text and towards the sound - is to get them working with these materials as heard objects. We are going to engage them in the medium. They are going to get their hands dirty. We are going to take sound - which might seem abstract and amorphous - and make it something they can touch, take apart, and reassemble. They are going to think about sound as something concrete and constructed by engaging in that very act of construction.</p>

<p><img src="/assets/images/nemla/slide04.jpg" alt="audacity icon slide" /></p>

<p>One approach to this might be to use a tool like <a href="http://www.audacityteam.org/">Audacity</a>. If you’re not familiar, Audacity is an open source tool that lets you input sound clips and then edit them in a pared down interface. If you have an MP3 on your computer, right click it to open it in Audacity, and you will get something like this:</p>

<p><img src="/assets/images/nemla/slide05.jpg" alt="waveform in audacity" /></p>

<p>A waveform. Already we are a bit alienated from the text because this visualization doesn not really allow you to access the text of the poem as such. Interacting with the poem becomes akin to touching a visual representation of sound waves. Now, you can’t do everything in Audacity, and that’s what I like about it. When I was a music student in college I remember getting introduced to some pretty beefy sound software - <a href="http://www.avid.com/pro-tools">Pro Tools</a> and <a href="http://www.motu.com/products/software/dp">Digital Performer</a>. I also remember feeling pretty overwhelmed by what they had to offer. So many options! Hundreds and thousands of things to click on! What I like about Audacity is that it is a bit more stripped down. Instead of giving you all the potential options for working with sound, it does a smaller subset really well. Record, edit, mix, etc. Audacity is also open source, so it is free while the other ones are quite expensive.</p>

<p><img src="/assets/images/nemla/slide06.jpg" alt="first assignment in audacity" /></p>

<p>I would suggest having your students engage with recordings using this software. Here is an example assignment you might put together that asks them to put together an audio essay. Using Audacity, I would have them assemble their own sound recording that mixes in examples from other poetry recordings under examination. You might frame the exercise by having them work through a tutorial on editing audio with audacity that I put together for <a href="https://programminghistorian.org/lessons/editing-audio-with-audacity">The Programming Historian</a>. The Programming Historian provides tutorials for a variety of digital humanities tools and methods, so this piece on Audacity is meant for absolute beginners. It coaches people through working with the interface, and, over the course of the lesson, readers produce a small podcast.</p>

<p>The lesson asks readers to use a stub Bach recording, but I would adapt it to have students assemble an essay that analyzes a poetic sound recording relevant to the course material. Instead of writing a paper on a recording, the students actually integrate their audible evidence into a new sound object, assembling the podcast by hand. Citation and description can join together in this model, and I can imagine having a student pay close attention to the audible qualities of the sounds they are discussing. The sky is the limit, but, personally, I like to imagine students analyzing TS Eliot’s voice by mimicking his style. Or you could imagine an analysis of his accent that tries to position his sense of locality, nation, and the globe by examining clips from a number of his recordings alongside clips of other speakers from around the world.</p>

<p><img src="/assets/images/nemla/slide07.jpg" alt="pros and cons of audacity" /></p>

<p>I see several benefits to having students work in this way. Students could learn a lot about Audacity producing these kinds of audio essays, and anyone planning to work with audio in the future should possess some experience with this fundamental tool. The wealth of resources for Audacity mean that it is well-suited for beginners. There are far more substantial tutorials for the software besides my own, so students would be well supported to take on this reasonably intuitive interface.</p>

<p>But there are also limitations here. For one, this type of engagement is a really slow process. Your students, after all, are engaging with a medium that they can only really experience in time. If you are working with four hours of recordings, you really have to have listened to all or most of that sound to work with it in a meaningful way. And to make anything useful, they will probably want to have listened to it multiple times and have made some notes. That is an extraordinary amount of time and energy, and we might be able to do better.</p>

<p>In addition, the assembling process is deliberate. You are asking students to put together clips bit by bit in accordance with a particular reading. And this is the real problem that I want to address - the medium here is unlikely to show you anything new. It is meant to illustrate a reading you already have. You want to produce an interpretation, so you illustrate it with sound. The theory comes first - the praxis second.</p>

<p>So I want to ask: what are some other ways we can work with audio that might show us truly new things? And how can we get around the need to listen slowly? The <a href="https://blogs.ischool.utexas.edu/hipstas/publications/">work by Tanya Clement and HiPSTAS</a> offer compelling examples for distant listening and audio machine learning as answers to these questions. I want to offer an approach based on creativity and play. By embracing chance-based composition techniques at scale, we can start to develop more useful classroom assignments for audio.</p>

<p><img src="/assets/images/nemla/slide08.jpg" alt="deformance quotation" /></p>

<p>In shifting the interpretative dimensions in this way, I am drawing on an idea that comes from Jerome McGann and Lisa Samuels: deformance. At the heart of their essay on “<a href="http://www2.iath.virginia.edu/jjm2f/old/deform.html">Deformance and Interpretation</a>” is a quote from Emily Dickinson:</p>

<blockquote>
  <p>“Did you ever read one of her Poems backward, because the plunge from the front overturned you? I sometimes (often have, many times) have — a Something overtakes the Mind –”</p>
</blockquote>

<p>McGann and Samuels take her very literally, and they proceed to model how reading a poem backwards, line by line, can offer generative readings. This process illustrated two main ideas. The first was that reading destructively and deformatively in this way exposes new parts of the poetry that you might not otherwise notice. You get a renewed sense of the constructedness of a poem, and the materiality of it rises to the surface. By reshaping, warping, or demolishing a poem, you actually learned something about its material components and, thus, the original poem itself. The second idea was that all acts of interpretation remade their objects of study in this way. By interpreting, the poem and our sense of it changed. So destructive reading performs this process in the fullest sense by enacting an interpretation that literally changes the shape or nature of the object. For a fuller history and more satisfying explanation of the interpretive dimensions of audio deformance for research, check out “<a href="https://soundstudiesblog.com/2016/10/24/in-different-voices-vocal-deformance-and-performative-speech/">Vocal Deformance and Performative Speech, or In Different Voices!</a>” posted by Marit J. MacArthurt and Lee M. Miller over at <em>Sounding Out</em>. They also work with T.S. Eliot, though they they are working with recordings by him rather than those done by amateur readers.</p>

<p><img src="/assets/images/nemla/slide09.jpg" alt="cut up poetry" /></p>

<p>In thinking about this performative form of reading, I was struck at how similar it sounded to cut-up poetry, the practice of slicing apart and rearranging the text of a poem so as to create new materials as popularized by the Dadaists and William S. Burroughs. To make the link to the Audacity assignments I was discussing earlier, I became interested in how this kind of performative, random, and destructive form of reading might extend the experiments in listening that I discussed with Audacity. Rather than having students purposefully rearrange a sound recording themselves, perhaps we could release our control over the audio artifact. We would still engage students in the texture of the medium, but we would ask them to let their analysis and their manifestation of that thinking grow a little closer together. We would invite play and the unknown into the process.</p>

<p><img src="/assets/images/nemla/slide10.jpg" alt="provocations" /></p>

<p>So we will ask them to engage in the material aspects of poetry by interacting with it as a physical, constructed thing. But the engagement will be different. We will have them engage. We will have them warp. We will have them cut up. Rather than using scissors, we will let a computer program do the slicing for us. The algorithm that goes into that program will offer our interpretive intervention, and we will surrender control over it just a bit, with the understanding that doing so will offer up new interpretive dimensions later on.</p>

<p><img src="/assets/images/nemla/slide11.jpg" alt="python as a solution" /></p>

<p>My approach to this was to use computer programs written in Python - a tool that allowed ways around some of the limitations that I already noted for working with Audacity. By working with a computer program I was able to produce something that could read hours of audio far quicker than I could. Python also allowed me to repurpose extant audio software packages to manipulate the audio according to my own algorithms/interpretations. In this case, I was working with <a href="https://github.com/antiboredom/audiogrep">Audiogrep</a> and <a href="https://github.com/jiaaro/pydub">Pydub</a>. I did not need to reinvent the wheel, as I could let these packages do the heavy lifting for me. In fact, a lot of what I did here was just manipulate the extant documentation and code examples for the tools in ways that felt intellectually satisfying. The programming became an interpretive intervention in its own right that, as I will show, brought with it all sorts of serendipitous problems. All the code I used is available <a href="https://gist.github.com/walshbr/cbcdabc92995334ae52414d048ae5d92">as a gist</a> – it took some tinkering to get running, and it will not run for you out of the box without some manipulation. So feel free to get in touch if you wanted to try these things yourself. I can offer lessons learned!</p>

<p>In working with these tools, it quickly became clear that I needed to spend time exploring their possibilities, playing with to see what I could do. In that spirit, I will do something a bit different for the remainder of this piece. Rather than give an assignment example up front, I will share some of the things you can do to audio with Python and why they might be meaningful from an interpretive standpoint. Then I will offer reflections at the end. My workflow was as follows:</p>

<ol>
  <li>I assembled a small corpus of sound artifacts – in this case, all the recordings of The Waste Land recorded by amateur readers on <a href="https://librivox.org/">LibriVox</a>.</li>
  <li>I installed and configured the packages to get my Python scripts running.</li>
  <li>Then I started playing, exploring all the options these Python packages had.</li>
</ol>

<p>The first step of this process involves having the script read in all the recordings so that they can be transcribed. To do so, Audiogrep calls another piece of software called <a href="https://github.com/cmusphinx/pocketsphinx">Pocketsphinx</a> behind the scenes. The resulting transcriptions look like this:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>if it is a litter box recording
&lt;s&gt; 4.570 4.590 0.999800
if 4.600 4.810 0.489886
it 4.820 4.870 0.127322
is 4.880 4.960 0.662690
a 4.970 5.000 0.372315
litter 5.010 5.340 0.939406
box 5.350 5.740 0.992825
recording(2) 5.750 6.360 0.551414
</code></pre></div></div>

<p>The results show us that audio transcription, obviously, is a vexed process, just as OCR is a troubled way of interacting with print text. What you see here is a segment from the transcription along with a series of words that the program thinks it heard. In this case, the actual audio “This is a librivox recording” becomes heard by the computer as “If it is a litter box recording” Although my cat might be proud, this shows pretty clearly that the process of working algorithmically is inaccurate. In this case, listening with Python exposes what Ryan Cordell or Matthew Kirschenbaum might describe as the traces that the digital methods leave on the artifacts as we work with them. Here is the longer excerpt of the Audiogrep transcription for this particular recording of <em>The Wasteland</em>:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>the wasteland
i t. s. eliot
if it is a litter box recording
oliver box recordings are in the public domain
for more information or to volunteer
these visits litter box dot org
according my elizabeth client
the wasteland
i t. s. eliot
section one
ariel of the dead
april is the cruelest month
reading lie lacks out of the dead land mixing memory and designer
staring down roots with spring rain
winter kept us warm
having earth and forgetful snow
feeding a little life with tribes two birds
</code></pre></div></div>

<p>Lots of problems here. We could say that to listen algorithmically is to do entwine signal with noise, and, personally, I think this is great! From an interpretive standpoint, this exposes artifacts from the remaking process and shows how each intervention in the text remakes it. In a deformance theory of interpretation, you cannot work with a text without changing it, and the same is true of audio. In this case, the object literally transforms. Also note that multiple recordings will be transcribed differently. Every attempt to read the text through Python produces a new text, right in line with the performative interpretations that McGann and Samuels describe. Regional accents would produce new and different texts depending on the program’s ability to map them onto recognized words.</p>

<p>But you can do much more than just transcribe things with Python. When this package transcribes words, it tags each of the words with a timestamp. So you can disassemble and reassemble the text at will, using these timestamps as hooks for guiding the program. Rather than painstakingly assembling readings by hand, you could search across the recording in the same way that you might a text file. Here is an example of what you can do with one of Audiogrep’s baked in functions - you can create supercuts of a single word or cluster of related words:</p>

<audio controls="">
	<source src="/assets/mp3s/nemla/voice-sound-supercut.mp3" type="audio/mpeg" />
	<source src="/assets/ogg/nemla/voice-sound-supercut.ogg" type="audio/ogg" />Your browser does not support this audio format.
</audio>

<p>Sam Lavigne has other examples of similar audio mashups on <a href="http://lav.io/2015/02/audiogrep-automatic-audio-supercuts/">his site</a> describing what you can do with Audiogrep. In this case, I’ve searched across all the recordings for instances of “sound” and “voice” and mashed up all those instances. You can also use regular expressions to search, allowing for pretty complicated ways of navigating a recording. Keep in mind that this is only searching across the transcriptions, which we already noted were inaccurate. So it is proper to say that this method is not telling you something about the text so much as about the recordings themselves. The program is producing a performative reading of what it understands the texts behind the audio to be. The script allows you to compare multiple recordings in a particular way that would be pretty painstaking to do by hand, but the process is imperfect and prone to error. Still, I find this to be a useful tool for collating the intonations and cadences of different readers. I am particularly interested in how amateur readers perform and re-perform the text in their own unique ways. This method allows me to ask, for example, whether all readers sonically interpret a particular line in the same or different ways.</p>

<p>You can also have the program create your own, new sound artifacts drawing upon the elements of the originals. Since we have all the transcriptions, we can also create performative readings of our own. Rather than getting all instances of one word, we can put together a new text and have it spoken through the individual sound clips drawn from our input. Before playing the result, read through what I wrote.</p>

<blockquote>
  <p>Approaching sound in this way is a way for our students to reconstitute their own ideas through the very sound artifacts that they are studying. In so doing, they learn to consider them as sound, as material objects that can be turned over, re-examined, disrupted, and reassembled. But look at how much is gone. How much gets lost. The recording is notable for its absences, its gaps.</p>
</blockquote>

<p>That should give you a hint about what kind of recording is about to come out. What follows is the program’s best attempt to recreate my passage using only words spoken by LibriVox readers as they perform Eliot’s text.</p>

<audio controls="">
	<source src="/assets/mp3s/nemla/speaking-with-text.mp3" type="audio/mpeg" />
	<source src="/assets/ogg/nemla/speaking-with-text.ogg" type="audio/ogg" />Your browser does not support this audio format.
</audio>

<p>The recording itself performs the idea, which is that working in Python in this way produces a reading that is somewhat out of control of the user. You cannot really account ahead of time for what will be warped and misshaped, but some distortion is inevitable. By passing the program the passage, it will search through for instances of each word and try to reassemble them into a whole. The reading becomes the recording. But we are asking the computer to do something when it does not have all the elements it needs to complete the task - we have asked it build a house, but we have given it no material for doors or windows. The result is a garbled mess, but you can still make out a few words here and there that are familiar. We hear a few things that are recognizable, but we also get a lot of silences and noise, what we might think of as the frictions produced by the gaps between what the script recognizes correctly and what it does not. The result is sound art as much as sound interpretation.</p>

<p>One last one. This one is a bit frightening.</p>

<audio controls="">
	<source src="/assets/mp3s/nemla/demon-voice.mp3" type="audio/mpeg" />
	<source src="/assets/ogg/nemla/demon-voice.ogg" type="audio/ogg" />Your browser does not support this audio format.
</audio>

<p>While trying to mash up all the silences in the recording to get a supercut of people breathing, I made a conversion error. Because of my mistake, I accidentally dropped a millisecond every five or six milliseconds in the recording rather than dropping only the pieces of spoken word. From this I learned how to make any recording sound like a demon. I think moments of serendipity like this are crucial, because they expose the recording as a recording. This effect almost sounds analogous to the sort of artifacts that might get accidentally created in the recording process. The process of approaching the recording leaves nothing unchanged, but, if we are mindful of these transformations, we can use them in the service of discovery.</p>

<p><img src="/assets/images/nemla/slide17.jpg" alt="reviewing what you can do with Python" /></p>

<p>So, to review: you can use Python to create supercuts of particular words, to perform readings of a text, to expose artifacts from the recording and transcription process, or to create demons. So my assignment for python might go something like this.</p>

<p><img src="/assets/images/nemla/slide18.jpg" alt="sample (joke) assignment with Python audio" /></p>

<p>Take some recordings and play around. I think you get the most out of a research method like this by letting the praxis generate the theory. Then let the outcomes reflect and revise the theory. Your students can serendipitously learn new things from these sorts of experiments, even if they might seem silly. Instead of shying away from the failures involved in transforming sound recordings into transcriptions and back again, I propose that we instead take a Joycean approach that “errors are volitional and are the portals of discovery.” The exercise could ask you to consider the traces of digital remediation that are present in the artifacts themselves. Or, it could generate a discussion of regionalism and accents of the Librivox participants that threw the transcriber off. To go further (on the excellent question/suggestion of a NEMLA audience member), this process could expose the fact that, in transcribing audio, the program favors particular pronunciations and silences those voices who do not accord with its linguistic sense of “proper” English. You might get a new sense of the particular vocabulary of recorded words in a text, and what it leaves out. Or you might get a renewed sense of how interpretation is a two-way street that changes our texts as we take them in.</p>

<p><img src="/assets/images/nemla/slide19.jpg" alt="pros and cons of using python for this" /></p>

<p>So Python offers some robust ways of working with audio through some packages that are ready to go. This lets you scale up quickly and try new things, but it is worth noting that these methods require far more technical overhead than using Audacity. For this reason, I mentioned training wheels above. Depending on your course, it might be too much to ask students to program in Python from scratch for an assignment like this. So you might offer them starter functions or detailed guides so they do not need to implement the whole thing themselves. The hands-off approach here might be more than some instructors or researchers are willing to allow. Furthermore, while I do think these methods are appropriate for scaling up an examination of audio recordings to compare many different audio artifacts, there are <a href="https://github.com/jiaaro/pydub/issues/135">important limitations</a> in the Python audio packages that, without significant tinkering, limit the size of the audio corpus you can work with.</p>

<p>For me, though, the possibilities of these approaches are generative enough to work around these limitations. Methods like these are useful for exposing students to sound archives as more than just pieces of cultural history but also as materials to be used, re-used, and remixed into their own work. I have deliberately chosen as my examples here only recordings of texts as given by amateur readers to suggest that these materials have always been performed and re-preformed. The assignments above ask students to place themselves in this tradition of recreation, and the approach invites them to view these interventions with a sense of exploration and humor.</p>
]]></content>
  </entry>
  
</feed>
