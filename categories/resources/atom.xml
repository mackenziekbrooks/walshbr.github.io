<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: resources | Brandon Walsh]]></title>
  <link href="http://walshbr.com/categories/resources/atom.xml" rel="self"/>
  <link href="http://walshbr.com/"/>
  <updated>2019-06-20T19:28:02+00:00</updated>
  <id>http://walshbr.com/</id>
  <author>
    <name><![CDATA[{"name"=>"Brandon Walsh", "url"=>"https://twitter.com/mdo", "email"=>"walsh@virginia.edu"}]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Ripper Press Reports Dataset]]></title>
    <link href="http://walshbr.com/blog/ripper-dataset/"/>
    <updated>2016-12-12T09:51:00+00:00</updated>
    <id>http://walshbr.com/blog/ripper-dataset</id>
    <content type="html"><![CDATA[<p><em>[Crossposted on the <a href="https://digitalhumanities.wlu.edu/blog/2016/12/12/ripper-dataset/">WLULDH blog</a>.]</em></p>

<p>Update: since posting this, <a href="http://laurabmcgrath.com/">Laura McGrath</a> reached out about finding an error in the CSV version of the data. The version linked to here should be cleaned up now. In addition, you will want to follow steps at the end of this post if using the CSV file in Excel. And thanks to <a href="https://digitalhumanities.wlu.edu/blog/author/mackenzie-brooks/">Mackenzie Brooks</a> for her advice on working with CSV files in Excel.</p>

<p>This semester I have been co-teaching a course on “Scandal, Crime, and Spectacle in the Nineteenth Century” with <a href="https://www.wlu.edu/directory/profile?ID=x2047">Professor Sarah Horowitz</a> in the history department at W&amp;L. We’ve been experimenting with ways to make the work we did for the course available for others beyond our students this term, which led to an <a href="/blog/text-analysis-coursebook/">open coursebook on text analysis</a> that we used to teach some basic digital humanities methods.</p>

<p>I’m happy to make available today another resource that has grown out of the course. For their final projects, our students conducted analyses of a variety of historical materials. One of our student groups was particularly interested in <a href="http://casebook.org/press_reports/">Casebook: Jack the Ripper</a>, a site that gathers transcriptions of primary and secondary materials related to the Whitechapel murders. The student group used just a few of the materials on the site for their analysis, but they only had the time to copy and paste a few things from the archive for use in <a href="http://voyant-tools.org/">Voyant</a>. I found myself wishing that we could offer a version of the site’s materials better formatted for text analysis.</p>

<p>So we made one! With the permission of the editors at the Casebook, we have scraped and repackaged one portion of their site, the collection of press reports related to the murders, in a variety of forms for digital researchers. More details about the dataset are below, and we’ve drawn from the descriptive template for datasets used by Michigan State University while putting it together. Just write to us if you’re interested in using the dataset - we’ll be happy to give you access to them under the terms described below. And also feel free to get in touch if you have thoughts about how to make datasets like this more usable for this kind of work. We’re planning on using this dataset and others like it in future courses here at W&amp;L, so stay tuned for more resources in the future.</p>

<hr />

<p><strong>Title</strong></p>

<p>Jack the Ripper Press Reports Dataset</p>

<p><strong>Download</strong></p>

<p>The dataset can be downloaded <a href="https://wlu.box.com/s/vfywfpwrivpb7iqc681mzu42tqjez0q9">here</a>. Write walshb@wlu.edu if you have any problems accessing the dataset. This work falls under a <a href="https://creativecommons.org/licenses/by-nc/2.0/">cc by-nc license</a>. Anyone can use this data under these terms, but they must acknowledge, both in name and through hyperlink, <a href="http://casebook.org/press_reports/">Casebook: Jack the Ripper</a> as the original source of the data.</p>

<p><strong>Description</strong></p>

<p>This dataset features the full texts of 2677 newspaper articles between the years of 1844 and 1988 that reference the Whitechapel murders by Jack the Ripper. While the bulk of the texts are, in fact, contemporary to the murders, a handful of them skew closer to the present as press reports for contemporary crimes look back to the infamous case. The wide variety of sources available here gives a sense of how the coverage of the case differed by region, date, and publication.</p>

<p><strong>Preferred Citation</strong></p>

<p>Jack the Ripper Press Reports Dataset, Washington and Lee University Library.</p>

<p><strong>Background</strong></p>

<p>The Jack the Ripper Press Reports Dataset was scraped from <a href="https://casebook.org/">Casebook: Jack the Ripper</a> and republished with the permission of their editorial team in November 2016. The Washington and Lee University Digital Humanities group repackaged the reports here so that the collected dataset may be more easily used by interested researchers for text analysis.</p>

<p><strong>Format</strong></p>

<p>The same dataset exists here organized in three formats: two folders, ‘by_journal’ and ‘index’, and a CSV file.</p>

<ul>
  <li>by_journal: organizes all the press reports by journal title.</li>
  <li>index: all files in a single folder.</li>
  <li>casebook.csv: a CSV file containing all the texts and metadata.</li>
</ul>

<p>Each folder has related but slightly different file naming conventions:</p>

<ul>
  <li>by_journal:
    <ul>
      <li>journal_title/YearMonthDayPublished.txt</li>
      <li>eg. augusta_chronicle/18890731.txt</li>
    </ul>
  </li>
  <li>index:
    <ul>
      <li>journal_title_YearMonthDayPublished.txt</li>
      <li>eg. augusta_chronicle_18890731.txt</li>
    </ul>
  </li>
</ul>

<p>The CSV file is organized according to the following column conventions:</p>

<ul>
  <li>id of text, full filename from within the index folder, journal title, publication date, text of article</li>
  <li>eg. 1, index/august_chronicle_18890731.txt, augusta_chronicle, 1889-07-31, “lorem ipsum…”</li>
</ul>

<p><strong>Size</strong></p>

<p>The zip file contains two smaller folders and a CSV file. Each of these contains the same dataset organized in slightly different ways.</p>

<ul>
  <li>by_journal - 24.9 MB</li>
  <li>index of all articles- 24.8 MB</li>
  <li>casebook.csv - 18.4 MB</li>
  <li>Total: 68.1 MB uncompressed</li>
</ul>

<p><strong>Data Quality</strong></p>

<p>The text quality here is high, as the Casebook contributors transcribed them by hand.</p>

<p><strong>Acknowledgements</strong></p>

<p>Data collected and prepared by Brandon Walsh. Original dataset scraped from <a href="http://casebook.org/press_reports/">Casebook: Jack the Ripper</a> and republished with their permission.</p>

<hr />

<p>If working with the CSV data in Excel, you have a few extra steps to import the data. Excel has character limits on cells and other configurations that will make things go sideways unless you take precautions. Here are the steps to import the CSV file:</p>

<ol>
  <li>Open Excel.</li>
  <li>Make a blank spreadsheet.</li>
  <li>Go to the Data menu.</li>
  <li>Click “Get External Data”.</li>
  <li>Select “Import Text File”.</li>
  <li>Navigate to your CSV file and select it.</li>
  <li>Select “Delimited” and hit next.</li>
  <li>In the next section, uncheck “Tab” and check “Comma”, click next.</li>
  <li>In the next section, click on the fifth column (the column one to the right of the date column).</li>
  <li>At the top of the window, select “Text” as the column data format.</li>
  <li>It will take a little bit to process.</li>
  <li>Click ‘OK’ for any popups that come up.</li>
  <li>It will still take a bit to process.</li>
</ol>

<p>Your spreadsheet should now be populated with the Press Reports data.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Introduction to Text Analysis: A Coursebook]]></title>
    <link href="http://walshbr.com/blog/text-analysis-coursebook/"/>
    <updated>2016-10-24T14:06:00+00:00</updated>
    <id>http://walshbr.com/blog/text-analysis-coursebook</id>
    <content type="html"><![CDATA[<p><em>[Crossposted on the <a href="http://digitalhumanities.wlu.edu/blog/2016/10/27/introduction-to-text-analysis-a-coursebook/">WLUDH blog</a>]</em></p>

<p>I am happy to share publicly the initial release of a project that I have been shopping around in various talks and presentations for a while now. This semester, I co-taught a course on “Scandal, Crime, and Spectacle in the 19th Century” with Professor Sarah Horowitz in the history department here at Washington and Lee University. The course counted as digital humanities credit for our students, who were given a quick and dirty introduction to text analysis over the course of the term. In preparing for the class, I knew that I wanted my teaching materials on text analysis to be publicly available for others to use and learn from. One option might be to blog aggressively during the semester, but I worried that I would let the project slide, particularly once teaching got underway. Early conversations with Professor Horowitz suggested, instead, that we take advantage of time that we both had over the summer and experiment. By assembling our lesson plans far in advance, we could collaboratively author them and share them in a format that would be legible for publication both to our students, colleagues, and a wider audience. I would learn from her, she from me, and the product would be a set of resources useful to others.</p>

<p>At a later date I will write more on the collaboration, particularly on how the co-writing process was a way for both of us to build our digital skill sets. For now, though, I want to share the results of our work - <a href="http://walshbr.com/textanalysiscoursebook/">Introduction to Text Analysis: A Coursebook</a>. The materials here served as the backbone to roughly a one-credit introduction in text analysis, but we aimed to make them as modular as possible so that they could be reworked into other contexts. By compartmentalizing text analysis concepts, tool discussions, and exercises that integrate both, we hopefully made it a little easier for an interested instructor to pull out pieces for their own needs. All our materials are on <a href="https://github.com/walshbr/textanalysiscoursebook/">GitHub</a>, so use them to your heart’s content. If you are a really ambitious instructor, you can take a look at our section on <a href="http://walshbr.com/textanalysiscoursebook/book/conclusion/adapting/">Adapting this Book</a> for information on how to clone and spin up your own copy of the text materials. While the current platform complicates this process, as I’ll mention in a moment, I’m working to mitigate those issues. Most importantly to me, the book focuses on concepts and tools without actually introducing a programming language or (hopefully) getting too technical. While there were costs to these decisions, they were meant to make any part of the book accessible for complete newcomers, even if they haven’t read the preceding chapters. The book is really written with a student audience in mind, and we have the cute animal photos to prove it. Check out the <a href="http://walshbr.com/textanalysiscoursebook/book/README/">Preface</a> and <a href="http://walshbr.com/textanalysiscoursebook/book/introduction/for-instructors/">Introduction</a> to the book for more information about the thinking that went into it.</p>

<p>The work is, by necessity, schematic and incomplete. Rather than suggesting that this be the definitive book on the subject (how could anything ever be?), we want to suggest that we always benefit from iteration. More teaching materials always help. Any resource can be a good one - bad examples can be productive failures. So we encourage you to build upon these materials in your courses, workshops, or otherwise. We also welcome feedback on these resources. If you see something that you want to discuss, question, or contest, please drop us a line on our <a href="https://github.com/walshbr/textanalysiscoursebook/issues">GitHub issues</a> page. This work has already benefited from the kind feedback of others, either <a href="http://walshbr.com/textanalysiscoursebook/book/acknowledgements/">explicit</a> or <a href="http://walshbr.com/textanalysiscoursebook/book/conclusion/resources/">implicit</a>, and we are happy to receive any suggestions that can improve the materials for others.</p>

<p>One last thing - this project was an experiment in open and collaborative publishing. In the process of writing the book, it became clear that the platform we used for producing it - <a href="https://www.gitbook.com/">GitBook</a> - was becoming a problem. The platform was fantastic for spinning up a quick collaboration, and it really paid dividends in its ease of use for writers new to Markdown and version control. But the service was new and under heavy development. Ultimately, the code was out of our control, and I wanted something more stable and more fully in my hands for long-term sustainability. I am in the process of transferring the materials to a Jekyll installation that would run off GitHub pages. Rather than wait for this final, archive version of the site to be complete, it seemed better to release this current working version out into the world. I will update all the links here once I migrate things over. If the current hosting site is down, you can download a PDF copy of the most recent version of the book <a href=" /assets/introduction-to-text-analysis.pdf">here</a>.</p>

<p>Update: I got around to doing that! You can find the new, improved, and more stable version of the site <a href="http://walshbr.com/textanalysiscoursebook/">here</a>.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Text Analysis Workshop: Four Ways to Read a Text]]></title>
    <link href="http://walshbr.com/blog/ways-to-read/"/>
    <updated>2016-09-21T11:51:00+00:00</updated>
    <id>http://walshbr.com/blog/ways-to-read</id>
    <content type="html"><![CDATA[<p><em>[Crossposted on the <a href="http://digitalhumanities.wlu.edu/blog/2016/09/22/text-analysis-workshop-four-ways-to-read-a-text/">WLUDH blog</a>.]</em></p>

<p>On Monday I visited <a href="http://library.wlu.edu/about/library-directory/mackenzie-brooks">Mackenzie Brooks</a>’s course on “Data in the Humanities” to introduce digital text analysis to her students. I faced a few challenges when planning for the visit:</p>

<ul>
  <li><strong>Scope</strong> - I had two hours for the workshop and a lot of material to cover. I was meant to introduce anything and everything, as much as I wanted in a general overview of text analysis.</li>
  <li><strong>Background</strong> - This course is an introductory digital humanities course that counts as a science credit at W&amp;L, so I assumed no prior knowledge of programming. Mackenzie will be covering some things with them later in the course, but at this stage I needed to avoid anything really technical.</li>
  <li><strong>Length</strong> - Two hours was both a lot of time and no time at all. It was certainly not enough time to teach anyone to program for the first time. As an aside, I often find it hard to gauge how much material is appropriate for anything longer than 75 minutes.</li>
  <li><strong>Content</strong> - Since this was meant to be a general overview of the field, I did not want to lean too heavily on analysis by tools. I worried that if I did so the takeaway for the students would be how to use the tools, not the underlying concepts that the tools aided them in exploring.</li>
</ul>

<p>I wound up developing a workshop I called “Introduction to Text Analysis: Four Ways to Read a Text.” Focusing on four ways meant that I felt comfortable cutting a section if things started to go long. It also meant that I was developing a workshop model that could easily fit varying lengths in the future. For example, I’ll be using portions of this workshop throughout my introduction to text analysis lectures in my own course this fall. The approach would necessarily be pretty distant - I couldn’t go into much detail for any one method in this time. Finally, I wanted the students to think about text analysis concepts first and then come to tools that would help them to do so, so I tried to displace the tools and projects from the conversation slightly. The hope was that, by enacting or intuiting the methods by hand first, the concepts would stick more easily than they might otherwise.</p>

<p>The basic structure of the workshop was this:</p>

<ol>
  <li>I introduce a basic methodology for reading.</li>
  <li>Students are presented with a handout asking them to read in a particular way with a prompt from me. They complete the exercise.</li>
  <li>We talk about the process. We clarify the concept a little more together, and the students infer some of the basic difficulties and affordances of the approach.</li>
  <li>Then I show a couple tools and projects that use that method for real results.</li>
</ol>

<p>The four ways of reading I covered were close reading, bags of words, topic modeling, and sentiment analysis. So, to use the topic modeling portion as an example, any one of those units looked something like this:</p>

<ol>
  <li>I note how, until now, we have been discussing how counting words gives us a sense of the overall topic or scope of the text. Over time and in close proximity, individual words combine to give us a sense of what a text is about.</li>
  <li>I give the students three paragraphs with the words scrambled and out of order (done pretty quickly in Python). I ask the students to get in groups and tell me what the underlying topics or themes are for each excerpt. They had to produce three single-word topics for each paragraph, and paragraphs could share topics.</li>
  <li>We talk about how were able to determine the topics of the texts even with the paragraphs virtually unreadable. Even out of order, certain words in proximity together suggest the underlying theme of a text. We can think of texts as made up of a series of topics like these, clusters of words that occur in noticeable patterns near one another. We have human limits as to how much we can comprehend, but computers can help us run similar, mathematical versions of the same process to find out what words occur near each other in statistically significant patterns. The results can be thought of as the underlying topics or discourses that make up a series of documents. A lot of hand waving, I know, but I am assuming here that students will examine topic modeling in more detail at a later date. Better, I think, to introduce the broad strokes than lose students in the details.</li>
  <li>I then share <a href="http://dsl.richmond.edu/dispatch/pages/intro">Mining the Dispatch</a> as an example of topic modeling in action to show the students the kinds of research questions that can be explored using this method.</li>
</ol>

<p>So, in essence, what I tried to do is create a hands-on approach to teaching text analysis concepts that is flexible enough to fit a variety of needs and contexts. My handouts and slides are all up on <a href="https://github.com/bmw9t/waystoread">a github repository</a>. Feel free to share, reuse, and remix them in any way you would like.</p>
]]></content>
  </entry>
  
</feed>
